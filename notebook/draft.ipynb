{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data structures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import fbeta_score, make_scorer, classification_report\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer\n",
    "\n",
    "# impute\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# compose\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# resampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, TomekLinks\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "# feature selection\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# pipeline\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# non-ensample algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ensample algorithms\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# mlflow \n",
    "import mlflow\n",
    "from mlflow.models import infer_signature, infer_pip_requirements\n",
    "\n",
    "# others\n",
    "import pickle, uuid\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from warnings import simplefilter\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF: prepare data to train model\n",
    "def prepare_data_to_train(path: str) -> dict:\n",
    "    materials = dict()\n",
    "    arr = pd.read_csv(path).values\n",
    "    ##\n",
    "    le = LabelEncoder()\n",
    "    X, y = arr[:, :-1], le.fit_transform(arr[:, -1])\n",
    "    ##\n",
    "    materials['X_train'], materials['X_test'], materials['y_train'], materials['y_test'] = train_test_split(X, y, test_size=0.3, stratify=y, random_state=7)\n",
    "    \n",
    "    return materials\n",
    "\n",
    "# UDF: load base model\n",
    "def load_base_models() -> list:\n",
    "    base_models = []\n",
    "    base_models.append(('LR', LogisticRegression(n_jobs=-1)))\n",
    "    base_models.append(('KNN', KNeighborsClassifier(n_jobs=-1)))\n",
    "    base_models.append(('SVM', SVC()))\n",
    "    base_models.append(('CART', DecisionTreeClassifier()))\n",
    "    base_models.append(('ET', ExtraTreesClassifier(n_jobs=-1)))\n",
    "    base_models.append(('RF', RandomForestClassifier(n_jobs=-1)))\n",
    "    base_models.append(('GB', GradientBoostingClassifier()))\n",
    "    base_models.append(('LGBM', LGBMClassifier(verbose=-1, n_jobs=-1)))\n",
    "    base_models.append(('XGB', XGBClassifier(n_jobs=-1)))\n",
    "\n",
    "    return base_models\n",
    "\n",
    "# UDF: get selected models\n",
    "def get_seleted_models(names: list) -> list:\n",
    "    base_models = load_base_models()\n",
    "    selected_base_models = []\n",
    "    ##\n",
    "    for name, model in base_models:\n",
    "        if name in names:\n",
    "            selected_base_models.append((name, model))\n",
    "\n",
    "    return selected_base_models\n",
    "\n",
    "# UDF: get kfold results\n",
    "def get_kfold_results(models: list, X: np.ndarray, y: np.ndarray) -> dict:\n",
    "    kfold_results = dict()\n",
    "    ##\n",
    "    for name, model in models:\n",
    "        cv_results = cross_val_score(model, X, y, \n",
    "                                     cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3), \n",
    "                                     scoring=make_scorer(fbeta_score, beta=2))\n",
    "        kfold_results[name] = cv_results\n",
    "        print(f'{name}: {cv_results.mean()} ({cv_results.std()})')\n",
    "\n",
    "    return kfold_results\n",
    "\n",
    "# UDF: plot kfold results\n",
    "def plot_kfold_results(kfold_results: dict, title: str=None):\n",
    "    data_to_plot = pd.DataFrame(kfold_results)\n",
    "    ##\n",
    "    sorted_idxes = data_to_plot.mean()\\\n",
    "        .sort_values(ascending=False).index.tolist()\n",
    "    data_to_plot = data_to_plot.reindex(sorted_idxes, axis=1)\n",
    "    ##\n",
    "    g = sns.boxplot(data_to_plot)\n",
    "    g.set_title(title, fontdict=dict(size=15))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# UDF: dump model\n",
    "def dump_model(model, path: str) -> None:\n",
    "    with open(path, 'wb') as output:\n",
    "        pickle.dump(obj=model, file=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name, model) -> None:\n",
    "        self.name, self.model = name, model\n",
    "        self.data, self.next = dict(), None\n",
    "        self.test: Callable[[dict], tuple[list, list]]\n",
    "\n",
    "    def validate(self):\n",
    "        passed, failed = self.test(self.data)\n",
    "        ###\n",
    "        if self.next != None:\n",
    "            self.next.data.update({'idxes': failed, \n",
    "                                'X': self.data['X']})\n",
    "        ###\n",
    "        if len(passed) != 0:\n",
    "            return [(self.name, self.model, passed)]\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitBinaryTree():\n",
    "    def __init__(self, left: list, right: list) -> None:\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def invoke_validation_of_branch(self, nodes: list, passed: dict) -> dict:\n",
    "        num_iters, i = len(nodes), 0\n",
    "        signal = len(nodes[i].data['idxes'])\n",
    "\n",
    "        while signal != 0:\n",
    "            passed[nodes[i].name] = nodes[i].validate()\n",
    "\n",
    "            i += 1\n",
    "            ## the bug is here\n",
    "            if i < num_iters: \n",
    "                signal = len(nodes[i].data['idxes'])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return passed\n",
    "    \n",
    "    def validate(self):\n",
    "        passed = dict()\n",
    "        self.invoke_validation_of_branch(self.left, passed)\n",
    "        self.invoke_validation_of_branch(self.right, passed)\n",
    "        ##\n",
    "        results = [result[0] for result in passed.values() if len(result) != 0]\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right = list(), list()\n",
    "\n",
    "def std_test(data: dict) -> tuple[list, list]:\n",
    "    idxes = np.array(data['idxes'])\n",
    "    mask = pd.isnull(data['X'][:, idxes]).sum(axis=0) == 0\n",
    "    passed, failed = idxes[mask].tolist(), idxes[~mask].tolist()\n",
    "\n",
    "    return passed, failed\n",
    "\n",
    "std = Node('std', StandardScaler())\n",
    "std.test = std_test\n",
    "\n",
    "impute = Node('impute', SimpleImputer())\n",
    "impute.test = lambda x: (x['idxes'], [])\n",
    "std.next = impute\n",
    "\n",
    "ohe = Node('ohe', OneHotEncoder(drop='first', sparse_output=False))\n",
    "ohe.test = lambda x: (x['idxes'], [])\n",
    "\n",
    "left.extend([std, impute])\n",
    "right.append(ohe)\n",
    "tree = InitBinaryTree(left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDC: base customized transformer for sequatial feature selection task\n",
    "class FSBaseTransformer(BaseEstimator, TransformerMixin):\n",
    "    ##\n",
    "    def __init__(self, transformers: dict, tree: InitBinaryTree) -> None:\n",
    "        self.transformers = transformers\n",
    "        self.tree = tree\n",
    "\n",
    "        return None\n",
    "    ##\n",
    "    def check_ndim(self, X: np.ndarray) -> tuple[np.ndarray, int | float]:\n",
    "        ndim = X.ndim\n",
    "        if ndim == 2:\n",
    "            return X, X.shape[1]\n",
    "        else:\n",
    "            return X.reshape(-1, 1), 1\n",
    "    ##\n",
    "    def detect_category(self, X: np.ndarray) -> tuple[np.ndarray, dict]:\n",
    "        X, num_iters = self.check_ndim(X)\n",
    "        ###\n",
    "        idxes = dict(num=[], cat=[])\n",
    "        ### \n",
    "        for i in range(num_iters):\n",
    "            try:\n",
    "                float(X[0, i])\n",
    "                idxes['num'].append(i)\n",
    "            except:\n",
    "                idxes['cat'].append(i)\n",
    "\n",
    "        return X, idxes\n",
    "    ##\n",
    "    def get_assigned_transformers(self, idxes: dict) -> list:\n",
    "        if len(idxes['cat']) == 0:\n",
    "            return self.num_pro\n",
    "        elif len(idxes['num']) == 0:\n",
    "            return self.cat_pro \n",
    "        else:\n",
    "            return self.num_pro + self.cat_pro\n",
    "    ##\n",
    "    def fit(self, X: np.ndarray, y=None):\n",
    "        self.ct = ColumnTransformer(self.assigned_transformers, remainder='passthrough')\\\n",
    "            .fit(X)\n",
    "        \n",
    "        return self\n",
    "    ##\n",
    "    def transform(self, X: np.ndarray, y=None):\n",
    "        X, _ = self.check_ndim(X)\n",
    "\n",
    "        return self.ct.transform(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "class test(FSBaseTransformer):\n",
    "    def fit(self, X: np.ndarray, y=None):\n",
    "        X, idxes = self.detect_category(X)\n",
    "        ## test\n",
    "        self.tree.left[0].data.update({'X': X, 'idxes': idxes['num']})\n",
    "        self.tree.right[0].data.update({'X': X, 'idxes': idxes['cat']})\n",
    "        passed = self.tree.validate()\n",
    "        print(passed)\n",
    "        ## test\n",
    "        self.num_pro = [('num_trans', self.transformers['num'], idxes['num'])]\n",
    "        self.cat_pro = [('cat_trans', self.transformers['cat'], idxes['cat'])] \n",
    "\n",
    "        self.assigned_transformers = self.get_assigned_transformers(idxes)\n",
    "\n",
    "        super().fit(X)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplefilter(action='ignore')\n",
    "\n",
    "materials = prepare_data_to_train(path='../cache/data/cleaned.csv')\n",
    "\n",
    "base_model = get_seleted_models(['LGBM'])\n",
    "\n",
    "transformers = test(transformers=dict(num=make_pipeline(SimpleImputer(), StandardScaler()), \n",
    "                                      cat=make_pipeline(OneHotEncoder(drop='first', sparse_output=False))), \n",
    "                                      tree=tree)\n",
    "\n",
    "pipeline = Pipeline([('trans', transformers)] + base_model)\n",
    "\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator=pipeline, k_features='best', forward=True, \n",
    "    verbose=2\n",
    ")\n",
    "sfs.fit(materials['X_train'], materials['y_train'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
