{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udf and udc\n",
    "import os, sys\n",
    "cwd = os.getcwd()\n",
    "os.chdir('../')\n",
    "path_to_src = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "if path_to_src not in sys.path:\n",
    "    sys.path.append(path_to_src)\n",
    "from src.notebook.support import *\n",
    "from src.mlflow.support import *\n",
    "\n",
    "# others\n",
    "from warnings import simplefilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load Dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# materials\n",
    "materials = prepare_data_to_train(path='../cache/data/cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MLflow</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local server\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000/')\n",
    "experiment_name = 'Feature engineering'\n",
    "try:\n",
    "    mlflow.create_experiment(name=experiment_name, artifact_location='../cache/mlflow/runs/')\n",
    "except:\n",
    "    mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LR && LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = mlflow.search_runs(\n",
    "    filter_string=\"tags.base_model = 'LR' and tags.pre_pro = 'si(mean)_qtt_ohe_smoteenn'\", \n",
    "    order_by=[\"metrics.val_fbeta DESC\"]\n",
    ")['run_id'].values[0]\n",
    "path = mlflow.artifacts.download_artifacts(f\"runs:/{run_id}/model/artifacts\")\n",
    "path_lr = {'feature_selector': f\"{path}/feature_selector.pkl\", \n",
    "           'model': f\"{path}/model.pkl\"}\n",
    "lr_as_base = FSBaseClassifier(path_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = mlflow.search_runs(\n",
    "    filter_string=\"tags.base_model = 'LGBM' and tags.pre_pro = 'si(mean)_qtt_ohe_smoteenn'\", \n",
    "    order_by=[\"metrics.val_fbeta DESC\"]\n",
    ")['run_id'].values[0]\n",
    "path = mlflow.artifacts.download_artifacts(f\"runs:/{run_id}/model/artifacts\")\n",
    "path_xgb = {'feature_selector': f\"{path}/feature_selector.pkl\", \n",
    "            'model': f\"{path}/model.pkl\"}\n",
    "lgbm_as_base = FSBaseClassifier(path_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBeta score: 0.0 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85      1552\n",
      "           1       0.00      0.00      0.00       561\n",
      "\n",
      "    accuracy                           0.73      2113\n",
      "   macro avg       0.37      0.50      0.42      2113\n",
      "weighted avg       0.54      0.73      0.62      2113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xxo/miniconda3/envs/mlops/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/xxo/miniconda3/envs/mlops/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/xxo/miniconda3/envs/mlops/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "stacking = StackingClassifier(estimators=[('LR', lr_as_base), ('LGBM', lgbm_as_base)],\n",
    "                              final_estimator=DecisionTreeClassifier(),\n",
    "                              stack_method='predict')\n",
    "stacking.fit(materials['X_train'], materials['y_train'])\n",
    "val_predictions = stacking.predict(materials['X_test'])\n",
    "val_fbeta = fbeta_score(materials['y_test'], val_predictions, \n",
    "                        beta=2)\n",
    "print(f\"FBeta score: {val_fbeta} \\n{classification_report(materials['y_test'], val_predictions)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
